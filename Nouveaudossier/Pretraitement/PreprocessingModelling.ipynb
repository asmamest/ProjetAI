{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee965777",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy pandas scikit-learn matplotlib seaborn tqdm pydicom opencv-python pathlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "755e8490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "PyTorch version: 2.7.1+cu118\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Classification BI-RADS Mammographique - Plan d'Excellence\n",
    "# Bas√© sur: \"Deep learning prediction of mammographic breast density...\"\n",
    "# (Scientific Reports, 2025)\n",
    "# ============================================================================\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pydicom\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Deep Learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "# Compatible imports pour diff√©rentes versions de torchvision\n",
    "try:\n",
    "    from torchvision.models import ResNet50_Weights, InceptionV3_Weights, DenseNet121_Weights\n",
    "    from torchvision.models import EfficientNet_B0_Weights, EfficientNet_B1_Weights\n",
    "    WEIGHTS_AVAILABLE = True\n",
    "except ImportError:\n",
    "    WEIGHTS_AVAILABLE = False\n",
    "    ResNet50_Weights = InceptionV3_Weights = DenseNet121_Weights = None\n",
    "    EfficientNet_B0_Weights = EfficientNet_B1_Weights = None\n",
    "\n",
    "# M√©triques & √©valuation\n",
    "from sklearn.metrics import average_precision_score, accuracy_score, f1_score, confusion_matrix\n",
    "from sklearn.metrics import cohen_kappa_score, precision_recall_curve, roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Configuration\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "print(f\"Device: {DEVICE}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b42e4629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Classes de pr√©traitement charg√©es\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 1. CHARGEMENT ET NORMALISATION DES DONN√âES\n",
    "# ============================================================================\n",
    "\n",
    "class MammographyDataProcessor:\n",
    "    \"\"\"\n",
    "    Charge et pr√©traite les mammographies DICOM/DCM\n",
    "    Changement automatique E: ‚Üí D:, gestion des images manquantes\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_dicom(file_path):\n",
    "        \"\"\"Charge une image DICOM et retourne numpy array (0-255)\"\"\"\n",
    "        try:\n",
    "            if not os.path.exists(file_path):\n",
    "                return None\n",
    "            ds = pydicom.dcmread(file_path)\n",
    "            image = ds.pixel_array.astype(np.float32)\n",
    "            # Normalisation 0-255\n",
    "            image = ((image - image.min()) / (image.max() - image.min() + 1e-8)) * 255.0\n",
    "            return image.astype(np.uint8)\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur chargement DICOM {file_path}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    @staticmethod\n",
    "    def histogram_equalization(image):\n",
    "        \"\"\"Histogram equalization (cf. article)\"\"\"\n",
    "        if image is None:\n",
    "            return None\n",
    "        return cv2.equalizeHist(image)\n",
    "    \n",
    "    @staticmethod\n",
    "    def preprocess_image(image_path, target_size=224):\n",
    "        \"\"\"\n",
    "        Pipeline complet de preprocessing:\n",
    "        - Change E: ‚Üí D:\n",
    "        - Charge DICOM\n",
    "        - Histogram equalization\n",
    "        - Resize\n",
    "        \"\"\"\n",
    "        # Changement E: ‚Üí D:\n",
    "        image_path = str(image_path).replace('E:\\\\', 'D:\\\\').replace('E:/', 'D:/')\n",
    "        \n",
    "        # Charge image\n",
    "        image = MammographyDataProcessor.load_dicom(image_path)\n",
    "        if image is None:\n",
    "            return None  # Pas de blocage, retourne None\n",
    "        \n",
    "        # Histogram equalization\n",
    "        image = MammographyDataProcessor.histogram_equalization(image)\n",
    "        \n",
    "        # Resize\n",
    "        image = cv2.resize(image, (target_size, target_size), interpolation=cv2.INTER_LINEAR)\n",
    "        \n",
    "        # Convertir en 3 canaux (RGB) pour les mod√®les\n",
    "        image = np.stack([image] * 3, axis=-1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        return image\n",
    "    \n",
    "    @staticmethod\n",
    "    def fix_csv_paths(df, old_prefix='E:\\\\', new_prefix='D:\\\\'):\n",
    "        \"\"\"Corrige les chemins dans le DataFrame\"\"\"\n",
    "        path_cols = [col for col in df.columns if 'Path' in col or 'path' in col]\n",
    "        for col in path_cols:\n",
    "            if col in df.columns and df[col].dtype == 'object':\n",
    "                df[col] = df[col].str.replace(old_prefix, new_prefix, regex=False)\n",
    "        return df\n",
    "\n",
    "# Test chargement donn√©es\n",
    "print(\"‚úì Classes de pr√©traitement charg√©es\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "163cffd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MammographyDataset(Dataset):\n",
    "    def __init__(self, df, image_col='ImagePaths', birads_col='BI_RADS',\n",
    "                 target_size=224, augment=False, max_views=4):\n",
    "        \n",
    "        self.df = df\n",
    "        self.image_col = image_col\n",
    "        self.birads_col = birads_col\n",
    "        self.target_size = target_size\n",
    "        self.augment = augment\n",
    "        self.max_views = max_views\n",
    "\n",
    "        # D√©finir les transformations selon le mode (train/val)\n",
    "        if self.augment:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.RandomHorizontalFlip(p=0.5),\n",
    "                transforms.RandomRotation(degrees=10),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                                   std=[0.229, 0.224, 0.225])\n",
    "            ])\n",
    "        else:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                                   std=[0.229, 0.224, 0.225])\n",
    "            ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        # Label - utiliser BI_RADS_Class si disponible, sinon mapper\n",
    "        if 'BI_RADS_Class' in row and not pd.isna(row['BI_RADS_Class']):\n",
    "            label = int(row['BI_RADS_Class'])\n",
    "        else:\n",
    "            label = map_birads_to_class(row[self.birads_col])\n",
    "            label = int(label) if label is not None else 0\n",
    "\n",
    "        images = []\n",
    "\n",
    "        # row[self.image_col] = liste de chemins DICOM (LCC, RCC, LMLO, RMLO...)\n",
    "        image_paths = row[self.image_col]\n",
    "        \n",
    "        # S'assurer que image_paths est une liste\n",
    "        if isinstance(image_paths, str):\n",
    "            image_paths = eval(image_paths) if '[' in image_paths else [image_paths]\n",
    "        \n",
    "        for path in image_paths:\n",
    "            if isinstance(path, str) and path.strip():\n",
    "                img = MammographyDataProcessor.preprocess_image(\n",
    "                    path,\n",
    "                    self.target_size\n",
    "                )\n",
    "            else:\n",
    "                img = None\n",
    "\n",
    "            # S√©curit√© si image corrompue ou absente\n",
    "            if img is None:\n",
    "                img = np.zeros(\n",
    "                    (self.target_size, self.target_size, 3),\n",
    "                    dtype=np.uint8\n",
    "            )\n",
    "\n",
    "            # Convertir numpy array en PIL Image pour les transformations\n",
    "            img_pil = Image.fromarray(img.astype('uint8'), 'RGB')\n",
    "            \n",
    "            # Appliquer transformations\n",
    "            img_tensor = self.transform(img_pil)\n",
    "            \n",
    "            images.append(img_tensor)\n",
    "\n",
    "        # Padding si nombre de vues < max_views\n",
    "        while len(images) < self.max_views:\n",
    "            images.append(torch.zeros(3, self.target_size, self.target_size))\n",
    "\n",
    "        # Stack final - (V, C, H, W) ‚Üí (C, V, H, W) pour les mod√®les CNN standards\n",
    "        images = torch.stack(images[:self.max_views])  # (V, C, H, W)\n",
    "        \n",
    "        # R√©organiser pour avoir (C, V, H, W) ou traiter chaque vue s√©par√©ment\n",
    "        # Pour ResNet/CNN standards, nous allons traiter chaque vue s√©par√©ment\n",
    "        # et concat√©ner les features plus tard dans le mod√®le\n",
    "        \n",
    "        return images, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26c3903b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Mod√®les BI-RADS configur√©s (ResNet50, Inception, DenseNet, EfficientNet)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 3. MOD√àLES - PRIORIT√â A (Baseline + R√©plication Article)\n",
    "# ============================================================================\n",
    "\n",
    "def get_weights(weights_enum):\n",
    "    \"\"\"Helper function pour obtenir les poids (compatible avec anciennes versions)\"\"\"\n",
    "    if WEIGHTS_AVAILABLE and weights_enum is not None:\n",
    "        return weights_enum\n",
    "    return None\n",
    "\n",
    "class BiRadsClassifier(nn.Module):\n",
    "    def __init__(self, backbone_name='resnet50', pretrained=True, num_classes=4, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.backbone_name = backbone_name\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # Load backbone\n",
    "        if backbone_name == 'resnet50':\n",
    "            weights = get_weights(ResNet50_Weights.IMAGENET1K_V2) if (pretrained and ResNet50_Weights) else None\n",
    "            self.backbone = models.resnet50(weights=weights)\n",
    "            in_features = self.backbone.fc.in_features\n",
    "            self.backbone.fc = nn.Identity()\n",
    "            \n",
    "        elif backbone_name == 'inception_v3':\n",
    "            weights = get_weights(InceptionV3_Weights.IMAGENET1K_V1) if (pretrained and InceptionV3_Weights) else None\n",
    "            self.backbone = models.inception_v3(weights=weights, aux_logits=False)\n",
    "            in_features = self.backbone.fc.in_features\n",
    "            self.backbone.fc = nn.Identity()\n",
    "            \n",
    "        elif backbone_name == 'densenet121':\n",
    "            weights = get_weights(DenseNet121_Weights.IMAGENET1K_V1) if (pretrained and DenseNet121_Weights) else None\n",
    "            self.backbone = models.densenet121(weights=weights)\n",
    "            in_features = self.backbone.classifier.in_features\n",
    "            self.backbone.classifier = nn.Identity()\n",
    "            \n",
    "        elif backbone_name == 'efficientnet_b0':\n",
    "            weights = get_weights(EfficientNet_B0_Weights.IMAGENET1K_V1) if (pretrained and EfficientNet_B0_Weights) else None\n",
    "            self.backbone = models.efficientnet_b0(weights=weights)\n",
    "            in_features = self.backbone.classifier[1].in_features\n",
    "            self.backbone.classifier = nn.Identity()\n",
    "        \n",
    "        # Attention multi-vue\n",
    "        self.view_attention = nn.Sequential(\n",
    "            nn.Linear(in_features, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "        \n",
    "        # Classifier head\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(in_features, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (batch_size, num_views, C, H, W)\n",
    "        \"\"\"\n",
    "        batch_size, num_views, C, H, W = x.shape\n",
    "        \n",
    "        # Extraire les features pour chaque vue\n",
    "        view_features = []\n",
    "        for v in range(num_views):\n",
    "            view = x[:, v, :, :, :]  # (batch_size, C, H, W)\n",
    "            features = self.backbone(view)  # (batch_size, in_features)\n",
    "            view_features.append(features)\n",
    "        \n",
    "        # Stack: (batch_size, num_views, in_features)\n",
    "        all_features = torch.stack(view_features, dim=1)\n",
    "        \n",
    "        # Calculer les poids d'attention pour chaque vue\n",
    "        attention_weights = self.view_attention(all_features)  # (batch_size, num_views, 1)\n",
    "        attention_weights = torch.softmax(attention_weights, dim=1)\n",
    "        \n",
    "        # Combinaison pond√©r√©e\n",
    "        weighted_features = (all_features * attention_weights).sum(dim=1)  # (batch_size, in_features)\n",
    "        \n",
    "        # Classification\n",
    "        logits = self.head(weighted_features)\n",
    "        return logits\n",
    "\n",
    "def create_model(model_name='resnet50', pretrained=True):\n",
    "    \"\"\"Factory function pour cr√©er mod√®les\"\"\"\n",
    "    model = BiRadsClassifier(backbone_name=model_name, pretrained=pretrained, num_classes=4)\n",
    "    return model.to(DEVICE)\n",
    "\n",
    "print(\"‚úì Mod√®les BI-RADS configur√©s (ResNet50, Inception, DenseNet, EfficientNet)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84e5b541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Trainer configur√© (avec Early Stopping + Class Weighting + Focal Loss)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 4. ENTRA√éNEMENT ET √âVALUATION\n",
    "# ============================================================================\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"Focal Loss pour imbalance classes\"\"\"\n",
    "    def __init__(self, alpha=None, gamma=2.0):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "    \n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = nn.functional.cross_entropy(inputs, targets, reduction='none')\n",
    "        p = torch.exp(-ce_loss)\n",
    "        loss = (1 - p) ** self.gamma * ce_loss\n",
    "        if self.alpha is not None:\n",
    "            loss = self.alpha[targets] * loss\n",
    "        return loss.mean()\n",
    "\n",
    "class Trainer:\n",
    "    \"\"\"\n",
    "    Entra√Æneur complet avec:\n",
    "    - Early stopping\n",
    "    - Class weighting pour imbalance\n",
    "    - M√©triques (AP, F1, Kappa, etc.)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, train_loader, val_loader, model_name='resnet50',\n",
    "                 lr=0.001, weight_decay=1e-4, use_focal=False, class_weights=None):\n",
    "        self.model = model\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.model_name = model_name\n",
    "        self.device = DEVICE\n",
    "        \n",
    "        self.optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            self.optimizer, mode='max', factor=0.5, patience=3\n",
    "        )\n",
    "        \n",
    "        if use_focal:\n",
    "            self.criterion = FocalLoss(gamma=2.0)\n",
    "        else:\n",
    "            if class_weights is not None:\n",
    "                class_weights = torch.tensor(class_weights, dtype=torch.float32).to(DEVICE)\n",
    "            self.criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "        \n",
    "        self.best_val_ap = -1\n",
    "        self.best_epoch = 0\n",
    "        self.history = {'train_loss': [], 'val_loss': [], 'val_ap': [], 'val_f1': []}\n",
    "    \n",
    "    def train_epoch(self):\n",
    "        \"\"\"Une epoch d'entra√Ænement\"\"\"\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        for images, labels in tqdm(self.train_loader, desc='Train'):\n",
    "            images, labels = images.to(self.device), labels.to(self.device)\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            logits = self.model(images)\n",
    "            loss = self.criterion(logits, labels)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        return total_loss / len(self.train_loader)\n",
    "    \n",
    "    def evaluate(self):\n",
    "        \"\"\"√âvaluation complet: AP, F1, Accuracy, Kappa\"\"\"\n",
    "        self.model.eval()\n",
    "        all_probs = []\n",
    "        all_labels = []\n",
    "        total_loss = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in tqdm(self.val_loader, desc='Val'):\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                \n",
    "                logits = self.model(images)\n",
    "                loss = self.criterion(logits, labels)\n",
    "                total_loss += loss.item()\n",
    "                \n",
    "                probs = torch.softmax(logits, dim=1)\n",
    "                all_probs.append(probs.cpu().numpy())\n",
    "                all_labels.append(labels.cpu().numpy())\n",
    "        \n",
    "        # Gestion du cas o√π val_loader est vide\n",
    "        if len(all_probs) == 0:\n",
    "            return {\n",
    "                'val_loss': float('inf'),\n",
    "                'ap_per_class': [0, 0, 0, 0],\n",
    "                'mean_ap': 0,\n",
    "                'accuracy': 0,\n",
    "                'f1': 0,\n",
    "                'kappa': 0\n",
    "            }, np.array([]), np.array([]), np.array([])\n",
    "        \n",
    "        all_probs = np.concatenate(all_probs, axis=0)\n",
    "        all_labels = np.concatenate(all_labels, axis=0)\n",
    "        preds = np.argmax(all_probs, axis=1)\n",
    "        \n",
    "        # M√©triques (cf. article)\n",
    "        # AP one-vs-rest pour chaque classe\n",
    "        labels_bin = label_binarize(all_labels, classes=[0, 1, 2, 3])\n",
    "        ap_scores = []\n",
    "        for i in range(4):\n",
    "            ap = average_precision_score(labels_bin[:, i], all_probs[:, i])\n",
    "            ap_scores.append(ap)\n",
    "        mean_ap = np.mean(ap_scores)\n",
    "        \n",
    "        accuracy = accuracy_score(all_labels, preds)\n",
    "        f1 = f1_score(all_labels, preds, average='weighted')\n",
    "\n",
    "        kappa = cohen_kappa_score(all_labels, preds)\n",
    "        \n",
    "        metrics = {\n",
    "            'val_loss': total_loss / len(self.val_loader),\n",
    "            'ap_per_class': ap_scores,\n",
    "            'mean_ap': mean_ap,\n",
    "            'accuracy': accuracy,\n",
    "            'f1': f1,\n",
    "            'kappa': kappa\n",
    "        }\n",
    "        \n",
    "        return metrics, all_probs, all_labels, preds\n",
    "    \n",
    "    def train(self, num_epochs=50, early_stopping_patience=10):\n",
    "        \"\"\"Entra√Ænement avec early stopping\"\"\"\n",
    "        patience_counter = 0\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs} - Model: {self.model_name}\")\n",
    "            print(f\"{'='*60}\")\n",
    "            \n",
    "            # Train\n",
    "            train_loss = self.train_epoch()\n",
    "            print(f\"Train Loss: {train_loss:.4f}\")\n",
    "            self.history['train_loss'].append(train_loss)\n",
    "            \n",
    "            # Evaluate\n",
    "            metrics, probs, labels, preds = self.evaluate()\n",
    "            val_loss = metrics['val_loss']\n",
    "            mean_ap = metrics['mean_ap']\n",
    "            \n",
    "            print(f\"Val Loss: {val_loss:.4f}\")\n",
    "            print(f\"Mean AP: {mean_ap:.4f} | Accuracy: {metrics['accuracy']:.4f}\")\n",
    "            print(f\"F1 (weighted): {metrics['f1']:.4f} | Kappa: {metrics['kappa']:.4f}\")\n",
    "            print(f\"AP per class: {[f'{x:.3f}' for x in metrics['ap_per_class']]}\")\n",
    "            \n",
    "            self.history['val_loss'].append(val_loss)\n",
    "            self.history['val_ap'].append(mean_ap)\n",
    "            self.history['val_f1'].append(metrics['f1'])\n",
    "            \n",
    "            # Early stopping\n",
    "            if mean_ap > self.best_val_ap:\n",
    "                self.best_val_ap = mean_ap\n",
    "                self.best_epoch = epoch\n",
    "                patience_counter = 0\n",
    "                # Sauvegarde meilleur mod√®le\n",
    "                torch.save(self.model.state_dict(), \n",
    "                          f'best_{self.model_name}_birads.pt')\n",
    "                print(f\"‚úì Meilleur AP trouv√©! Sauvegard√©.\")\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if patience_counter >= early_stopping_patience:\n",
    "                    print(f\"Early stopping apr√®s {epoch+1} epochs\")\n",
    "                    break\n",
    "            \n",
    "            # LR scheduling\n",
    "            self.scheduler.step(mean_ap)\n",
    "        \n",
    "        print(f\"\\n‚úì Entra√Ænement termin√©. Meilleur AP: {self.best_val_ap:.4f} (epoch {self.best_epoch+1})\")\n",
    "        return metrics, probs, labels, preds\n",
    "\n",
    "print(\"‚úì Trainer configur√© (avec Early Stopping + Class Weighting + Focal Loss)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41eaa580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì √âvaluateur configu√© (Confusion Matrix, PR curves, Training history)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 5. VISUALISATION & √âVALUATION AVANC√âE\n",
    "# ============================================================================\n",
    "\n",
    "class BiRadsEvaluator:\n",
    "    \"\"\"\n",
    "    √âvaluation compl√®te:\n",
    "    - Confusion matrix\n",
    "    - PR curves per class\n",
    "    - Calibration plots\n",
    "    - Grad-CAM (explainability)\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_confusion_matrix(labels, preds, title='Confusion Matrix'):\n",
    "        \"\"\"Confusion matrix 4x4\"\"\"\n",
    "        cm = confusion_matrix(labels, preds)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                   xticklabels=['BI-RADS 1', 'BI-RADS 2', 'BI-RADS 3', 'BI-RADS 4'],\n",
    "                   yticklabels=['BI-RADS 1', 'BI-RADS 2', 'BI-RADS 3', 'BI-RADS 4'])\n",
    "        plt.ylabel('True Label')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.title(title)\n",
    "        plt.tight_layout()\n",
    "        return plt.gcf()\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_pr_curves(labels, probs):\n",
    "        \"\"\"Precision-Recall curves par classe (comme article)\"\"\"\n",
    "        labels_bin = label_binarize(labels, classes=[0, 1, 2, 3])\n",
    "        class_names = ['BI-RADS 1', 'BI-RADS 2', 'BI-RADS 3', 'BI-RADS 4']\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "        axes = axes.ravel()\n",
    "        \n",
    "        for i in range(4):\n",
    "            precision, recall, _ = precision_recall_curve(labels_bin[:, i], probs[:, i])\n",
    "            ap = average_precision_score(labels_bin[:, i], probs[:, i])\n",
    "            \n",
    "            axes[i].plot(recall, precision, lw=2, label=f'AP={ap:.3f}')\n",
    "            axes[i].set_xlabel('Recall')\n",
    "            axes[i].set_ylabel('Precision')\n",
    "            axes[i].set_title(f'{class_names[i]} (OvR)')\n",
    "            axes[i].legend()\n",
    "            axes[i].grid()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_training_history(history, model_name='Model'):\n",
    "        \"\"\"Courbes d'apprentissage\"\"\"\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "        \n",
    "        # Loss\n",
    "        axes[0].plot(history['train_loss'], label='Train Loss')\n",
    "        axes[0].plot(history['val_loss'], label='Val Loss')\n",
    "        axes[0].set_xlabel('Epoch')\n",
    "        axes[0].set_ylabel('Loss')\n",
    "        axes[0].set_title(f'{model_name} - Loss')\n",
    "        axes[0].legend()\n",
    "        axes[0].grid()\n",
    "        \n",
    "        # AP\n",
    "        axes[1].plot(history['val_ap'], marker='o')\n",
    "        axes[1].set_xlabel('Epoch')\n",
    "        axes[1].set_ylabel('Mean AP')\n",
    "        axes[1].set_title(f'{model_name} - Validation AP')\n",
    "        axes[1].grid()\n",
    "        \n",
    "        # F1\n",
    "        axes[2].plot(history['val_f1'], marker='s')\n",
    "        axes[2].set_xlabel('Epoch')\n",
    "        axes[2].set_ylabel('F1 Score (weighted)')\n",
    "        axes[2].set_title(f'{model_name} - Validation F1')\n",
    "        axes[2].grid()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "    \n",
    "    @staticmethod\n",
    "    def print_detailed_metrics(labels, preds, probs, model_name='Model'):\n",
    "        \"\"\"Affiche rapport d√©taill√© (accuracy, precision, recall par classe)\"\"\"\n",
    "        from sklearn.metrics import classification_report\n",
    "        \n",
    "        class_names = ['BI-RADS 1', 'BI-RADS 2', 'BI-RADS 3', 'BI-RADS 4']\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"RAPPORT D√âTAILL√â - {model_name}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(classification_report(labels, preds, target_names=class_names))\n",
    "        \n",
    "        # AP per class\n",
    "        labels_bin = label_binarize(labels, classes=[0, 1, 2, 3])\n",
    "        print(f\"\\n{'Average Precision per Class'}\")\n",
    "        print(f\"{'-'*30}\")\n",
    "        for i in range(4):\n",
    "            ap = average_precision_score(labels_bin[:, i], probs[:, i])\n",
    "            print(f\"{class_names[i]}: {ap:.4f}\")\n",
    "\n",
    "print(\"‚úì √âvaluateur configu√© (Confusion Matrix, PR curves, Training history)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "970b9b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "√âTAPE 1: CHARGEMENT DONN√âES DEPUIS EXCEL COMPLET\n",
      "======================================================================\n",
      "\n",
      "üìÇ Fichier: D:\\Dataset\\Bilgi\\BilgiK√¨sm√¨na_Exceller\\final_dataset_all_patients.xlsx\n",
      "‚è≥ Chargement du fichier Excel complet...\n",
      "‚úÖ 8250 cas charg√©s!\n",
      "\n",
      "üìù Correction des chemins E: ‚Üí D:\n",
      "   ‚úì RCC_Path: 7144/8250 fichiers\n",
      "   ‚úì LCC_Path: 7145/8250 fichiers\n",
      "\n",
      "üìù Traitement des labels BI-RADS:\n",
      "   Labels originaux: ['BI-RADS4-5' 'BI-RADS1-2']\n",
      "   Distribution des classes:\n",
      "   - Classe 0: 4,125 cas (50.0%)\n",
      "   - Classe 3: 4,125 cas (50.0%)\n",
      "\n",
      "üìä Structure du DataFrame charg√©:\n",
      "   Forme: (8250, 11) (lignes √ó colonnes)\n",
      "   Colonnes pr√©sentes: ['CaseNumber', 'BI_RADS', 'Breast_Density', 'Age_Bin', 'Quadrant_Right', 'Quadrant_Left', 'RCC_Path', 'LCC_Path', 'RMLO_Path', 'LMLO_Path', 'BI_RADS_Class']\n",
      "\n",
      "üìã M√©tadonn√©es disponibles:\n",
      "   - Densit√© mammaire (A/B/C/D): {'B': 3146, 'C': 2776, 'D': 1225, 'A': 1103}\n",
      "   - √Çge: ['40-49', '50-59', '60-69', '70-79']\n",
      "\n",
      "‚úì V√©rification des images disponibles:\n",
      "   - RCC_Path: 7,144 images\n",
      "   - LCC_Path: 7,145 images\n",
      "   ‚Üí Total cas avec ‚â•1 image: 7,145/8250\n",
      "\n",
      "‚úì V√©rification de l'accessibilit√© (premiers 10 cas):\n",
      "\n",
      "üì∏ Configuration Multi-View (LCC, RCC, LMLO, RMLO)\n",
      "   ‚úì Cas valides: 4780/8250\n",
      "   ‚úì Exemple vues patient: ['D:\\\\Dataset\\\\Part_1\\\\845283972\\\\LCC.dcm', 'D:\\\\Dataset\\\\Part_1\\\\845283972\\\\RCC.dcm']\n",
      "   ‚úì Case 845283972: BI-RADS4-5\n",
      "   ‚úì Case 822688694: BI-RADS1-2\n",
      "   ‚úì Case 822696984: BI-RADS1-2\n",
      "   ‚úì Case 845280755: BI-RADS4-5\n",
      "   ‚úì Case 845282699: BI-RADS4-5\n",
      "   ‚úì Case 845282470: BI-RADS4-5\n",
      "   ‚úì Case 822670325: BI-RADS1-2\n",
      "   ‚úì Case 822697035: BI-RADS1-2\n",
      "   ‚úì Case 845284145: BI-RADS4-5\n",
      "   ‚úì Case 845285230: BI-RADS4-5\n",
      "\n",
      "üì∏ Configuration des images principales:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'# Utiliser LCC_Path, sinon RCC_Path, sinon RMLO_Path\\ndf[\\'ImagePath\\'] = df[\\'LCC_Path\\'].copy()\\nmask_empty = (df[\\'ImagePath\\'] == \\'\\')\\nif mask_empty.sum() > 0:\\n    df.loc[mask_empty, \\'ImagePath\\'] = df.loc[mask_empty, \\'RCC_Path\\']\\n    print(f\"   - {mask_empty.sum()} cas sans LCC_Path ‚Üí utilisation RCC_Path\")\\n\\nmask_empty = (df[\\'ImagePath\\'] == \\'\\')\\nif mask_empty.sum() > 0:\\n    df.loc[mask_empty, \\'ImagePath\\'] = df.loc[mask_empty, \\'RMLO_Path\\']\\n    print(f\"   - {mask_empty.sum()} cas sans RCC_Path ‚Üí utilisation RMLO_Path\")\\n\\n# Ajouter alias pour compatibilit√©\\nif \\'LCC_Path\\' not in df.columns or (df[\\'LCC_Path\\'] == \\'\\').all():\\n    df[\\'LCC_Path\\'] = df[\\'ImagePath\\']\\n\\nprint(f\"\\n{\\'=\\'*70}\")\\nprint(f\"‚úÖ DONN√âES FINALES CHARG√âES ET PR√âPAR√âES\")\\nprint(f\"{\\'=\\'*70}\")\\nprint(f\"Total cas: {len(df):,}\")\\nprint(f\"Colonnes cl√©s: {[\\'CaseNumber\\', \\'BI_RADS\\', \\'BI_RADS_Class\\', \\'Breast_Density\\', \\'LCC_Path\\']}\")\\nprint(f\"\\nAper√ßu des donn√©es:\")\\nprint(df[[\\'CaseNumber\\', \\'BI_RADS\\', \\'BI_RADS_Class\\', \\'Breast_Density\\', \\'LCC_Path\\']].head(10))\\n\\nprint(f\"\\n‚úì Donn√©es pr√™tes pour √âTAPE 2 (cr√©ation DataLoaders)\")\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 6. EXEMPLE D'UTILISATION COMPLET\n",
    "# ============================================================================\n",
    "\n",
    "# Suppose que tu charges un DataFrame avec colonnes:\n",
    "# - CaseNumber (ou ID)\n",
    "# - BI_RADS (label)\n",
    "# - LCC_Path (path to image)\n",
    "# - RCC_Path (optional)\n",
    "# - MLO_Path (optional)\n",
    "\n",
    "# √âTAPE 1: CHARGER LES DONN√âES DEPUIS EXCEL COMPLET\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"√âTAPE 1: CHARGEMENT DONN√âES DEPUIS EXCEL COMPLET\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ============================================================================\n",
    "# Chemin du fichier Excel avec toutes les donn√©es\n",
    "# ============================================================================\n",
    "xlsx_path = r'D:\\Dataset\\Bilgi\\BilgiK√¨sm√¨na_Exceller\\final_dataset_all_patients.xlsx'\n",
    "\n",
    "print(f\"\\nüìÇ Fichier: {xlsx_path}\")\n",
    "print(\"‚è≥ Chargement du fichier Excel complet...\")\n",
    "\n",
    "# Charger le fichier Excel\n",
    "df = pd.read_excel(xlsx_path)\n",
    "print(f\"‚úÖ {len(df)} cas charg√©s!\")\n",
    "\n",
    "# ============================================================================\n",
    "# Correction des chemins E: ‚Üí D:\n",
    "# ============================================================================\n",
    "print(f\"\\nüìù Correction des chemins E: ‚Üí D:\")\n",
    "\n",
    "path_columns = ['RCC_Path', 'LCC_Path']\n",
    "\n",
    "for col in path_columns:\n",
    "    if col in df.columns:\n",
    "        # Remplacer E: par D:\n",
    "        df[col] = df[col].fillna('').astype(str)\n",
    "        df[col] = df[col].str.replace('E:\\\\', 'D:\\\\', regex=False)\n",
    "        df[col] = df[col].str.replace('E:/', 'D:/', regex=False)\n",
    "        \n",
    "        # Compter chemins valides (non vides)\n",
    "        valid_paths = (df[col] != '').sum()\n",
    "        print(f\"   ‚úì {col}: {valid_paths}/{len(df)} fichiers\")\n",
    "\n",
    "# ============================================================================\n",
    "# Mapping des labels BI-RADS en classes (0-3)\n",
    "# ============================================================================\n",
    "print(f\"\\nüìù Traitement des labels BI-RADS:\")\n",
    "print(f\"   Labels originaux: {df['BI_RADS'].unique()}\")\n",
    "\n",
    "def map_birads_to_class(label):\n",
    "    \"\"\"\n",
    "    Mappe les groupes BI-RADS aux indices de classe:\n",
    "    - BI-RADS1-2 ‚Üí 0 (Faible densit√©)\n",
    "    - BI-RADS3   ‚Üí 1 (Densit√© h√©t√©rog√®ne)  \n",
    "    - BI-RADS4-5 ‚Üí 3 (Tr√®s dense)\n",
    "    \"\"\"\n",
    "    if pd.isna(label):\n",
    "        return None\n",
    "    \n",
    "    label = str(label).strip().upper()\n",
    "    \n",
    "    if '1-2' in label or 'BI-RADS1-2' in label:\n",
    "        return 0\n",
    "    elif '3' in label or 'BI-RADS3' in label:\n",
    "        return 1\n",
    "    elif '4-5' in label or 'BI-RADS4-5' in label:\n",
    "        return 3\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Cr√©er colonne de classe\n",
    "df['BI_RADS_Class'] = df['BI_RADS'].apply(map_birads_to_class)\n",
    "\n",
    "# Afficher distribution\n",
    "class_distribution = df['BI_RADS_Class'].value_counts().sort_index()\n",
    "print(f\"   Distribution des classes:\")\n",
    "for cls, count in class_distribution.items():\n",
    "    pct = (count / len(df)) * 100\n",
    "    print(f\"   - Classe {cls}: {count:,} cas ({pct:.1f}%)\")\n",
    "\n",
    "# ============================================================================\n",
    "# Afficher structure du DataFrame\n",
    "# ============================================================================\n",
    "print(f\"\\nüìä Structure du DataFrame charg√©:\")\n",
    "print(f\"   Forme: {df.shape} (lignes √ó colonnes)\")\n",
    "print(f\"   Colonnes pr√©sentes: {df.columns.tolist()}\")\n",
    "\n",
    "print(f\"\\nüìã M√©tadonn√©es disponibles:\")\n",
    "if 'Breast_Density' in df.columns:\n",
    "    print(f\"   - Densit√© mammaire (A/B/C/D): {df['Breast_Density'].value_counts().to_dict()}\")\n",
    "if 'Age_Bin' in df.columns:\n",
    "    print(f\"   - √Çge: {sorted(df['Age_Bin'].unique())}\")\n",
    "\n",
    "# ============================================================================\n",
    "# V√©rification des fichiers disponibles\n",
    "# ============================================================================\n",
    "print(f\"\\n‚úì V√©rification des images disponibles:\")\n",
    "\n",
    "# Compte images par type de vue\n",
    "for col in path_columns:\n",
    "    if col in df.columns:\n",
    "        available = (df[col] != '').sum()\n",
    "        print(f\"   - {col}: {available:,} images\")\n",
    "\n",
    "# Cas avec au moins une image\n",
    "has_image = (df[path_columns].astype(str) != '').any(axis=1).sum()\n",
    "print(f\"   ‚Üí Total cas avec ‚â•1 image: {has_image:,}/{len(df)}\")\n",
    "\n",
    "# V√©rifier fichiers existent (premiers 10)\n",
    "print(f\"\\n‚úì V√©rification de l'accessibilit√© (premiers 10 cas):\")\n",
    "# ============================================================================ \n",
    "# Cr√©ation des vues Multi-View par patient\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\nüì∏ Configuration Multi-View (LCC, RCC, LMLO, RMLO)\")\n",
    "\n",
    "view_columns = ['LCC_Path', 'RCC_Path', 'LMLO_Path', 'RMLO_Path']\n",
    "\n",
    "def collect_views(row):\n",
    "    views = []\n",
    "    for col in view_columns:\n",
    "        path = str(row.get(col, '')).strip()\n",
    "        if path and Path(path).exists():\n",
    "            views.append(path)\n",
    "    return views\n",
    "\n",
    "df['ImagePaths'] = df.apply(collect_views, axis=1)\n",
    "\n",
    "# Supprimer les cas sans aucune image valide\n",
    "before = len(df)\n",
    "df = df[df['ImagePaths'].apply(len) > 0].reset_index(drop=True)\n",
    "after = len(df)\n",
    "\n",
    "print(f\"   ‚úì Cas valides: {after}/{before}\")\n",
    "print(f\"   ‚úì Exemple vues patient:\", df['ImagePaths'].iloc[0])\n",
    "\n",
    "count_valid = 0\n",
    "for i, row in df.head(10).iterrows():\n",
    "    case_id = row['CaseNumber']\n",
    "    bi_rads = row['BI_RADS']\n",
    "    \n",
    "    # V√©rifier au moins un fichier\n",
    "    has_valid = False\n",
    "    for col in path_columns:\n",
    "        path = str(row.get(col, ''))\n",
    "        if path and path != '' and Path(path).exists():\n",
    "            has_valid = True\n",
    "            count_valid += 1\n",
    "            break\n",
    "    \n",
    "    status = \"‚úì\" if has_valid else \"‚úó\"\n",
    "    print(f\"   {status} Case {case_id}: {bi_rads}\")\n",
    "\n",
    "# ============================================================================\n",
    "# Pr√©parer LCC_Path comme image principale\n",
    "# ============================================================================\n",
    "print(f\"\\nüì∏ Configuration des images principales:\")\n",
    "\n",
    "\"\"\"# Utiliser LCC_Path, sinon RCC_Path, sinon RMLO_Path\n",
    "df['ImagePath'] = df['LCC_Path'].copy()\n",
    "mask_empty = (df['ImagePath'] == '')\n",
    "if mask_empty.sum() > 0:\n",
    "    df.loc[mask_empty, 'ImagePath'] = df.loc[mask_empty, 'RCC_Path']\n",
    "    print(f\"   - {mask_empty.sum()} cas sans LCC_Path ‚Üí utilisation RCC_Path\")\n",
    "\n",
    "mask_empty = (df['ImagePath'] == '')\n",
    "if mask_empty.sum() > 0:\n",
    "    df.loc[mask_empty, 'ImagePath'] = df.loc[mask_empty, 'RMLO_Path']\n",
    "    print(f\"   - {mask_empty.sum()} cas sans RCC_Path ‚Üí utilisation RMLO_Path\")\n",
    "\n",
    "# Ajouter alias pour compatibilit√©\n",
    "if 'LCC_Path' not in df.columns or (df['LCC_Path'] == '').all():\n",
    "    df['LCC_Path'] = df['ImagePath']\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"‚úÖ DONN√âES FINALES CHARG√âES ET PR√âPAR√âES\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Total cas: {len(df):,}\")\n",
    "print(f\"Colonnes cl√©s: {['CaseNumber', 'BI_RADS', 'BI_RADS_Class', 'Breast_Density', 'LCC_Path']}\")\n",
    "print(f\"\\nAper√ßu des donn√©es:\")\n",
    "print(df[['CaseNumber', 'BI_RADS', 'BI_RADS_Class', 'Breast_Density', 'LCC_Path']].head(10))\n",
    "\n",
    "print(f\"\\n‚úì Donn√©es pr√™tes pour √âTAPE 2 (cr√©ation DataLoaders)\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e138680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "√âTAPE 2: CR√âATION DATASETS & DATALOADERS\n",
      "======================================================================\n",
      "Train: 3346 | Val: 717 | Test: 717\n",
      "\n",
      "üìä Analyse des classes dans l'ensemble d'entra√Ænement:\n",
      "   Classe 0 (BI-RADS1-2): 2301 cas\n",
      "   Classe 3 (BI-RADS4-5): 1045 cas\n",
      "\n",
      "‚öñÔ∏è  Class weights (normalis√©s):\n",
      "   Classe 0: 0.6720\n",
      "   Classe 1: 0.9242\n",
      "   Classe 2: 0.9242\n",
      "   Classe 3: 1.4796\n",
      "‚úì Datasets cr√©√©s\n",
      "  Train loader: 419 batches\n",
      "  Val loader: 90 batches\n",
      "  Test loader: 90 batches\n"
     ]
    }
   ],
   "source": [
    "# √âTAPE 2: Cr√©er Datasets et DataLoaders\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"√âTAPE 2: CR√âATION DATASETS & DATALOADERS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Parametres\n",
    "BATCH_SIZE = 8\n",
    "TARGET_SIZE = 224\n",
    "TRAIN_SIZE = 0.7\n",
    "VAL_SIZE = 0.15\n",
    "\n",
    "# Split train/val/test (70:15:15)\n",
    "n = len(df)\n",
    "n_train = int(n * TRAIN_SIZE)\n",
    "n_val = int(n * VAL_SIZE)\n",
    "\n",
    "indices = np.arange(n)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "train_indices = indices[:n_train]\n",
    "val_indices = indices[n_train:n_train+n_val]\n",
    "test_indices = indices[n_train+n_val:]\n",
    "\n",
    "df_train = df.iloc[train_indices].reset_index(drop=True)\n",
    "df_val = df.iloc[val_indices].reset_index(drop=True)\n",
    "df_test = df.iloc[test_indices].reset_index(drop=True)\n",
    "\n",
    "print(f\"Train: {len(df_train)} | Val: {len(df_val)} | Test: {len(df_test)}\")\n",
    "\n",
    "# Calcule class weights pour imbalance\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "print(f\"\\nüìä Analyse des classes dans l'ensemble d'entra√Ænement:\")\n",
    "print(f\"   Classe 0 (BI-RADS1-2): {(df_train['BI_RADS_Class'] == 0).sum()} cas\")\n",
    "print(f\"   Classe 3 (BI-RADS4-5): {(df_train['BI_RADS_Class'] == 3).sum()} cas\")\n",
    "\n",
    "# Utiliser directement BI_RADS_Class pour les labels\n",
    "labels_train = df_train['BI_RADS_Class'].values\n",
    "labels_train = labels_train[~np.isnan(labels_train)].astype(int)\n",
    "\n",
    "if len(labels_train) > 0:\n",
    "    # Calcule poids uniquement pour classes pr√©sentes\n",
    "    unique_classes = np.unique(labels_train)\n",
    "    weights_computed = compute_class_weight('balanced', classes=unique_classes, y=labels_train)\n",
    "    \n",
    "    # Cr√©e array de 4 poids (un pour chaque classe BI-RADS)\n",
    "    class_weights = np.ones(4, dtype=np.float32)\n",
    "    for i, cls_id in enumerate(unique_classes):\n",
    "        class_weights[int(cls_id)] = weights_computed[i]\n",
    "    \n",
    "    # Normalise pour √©viter des gradients instables\n",
    "    class_weights = class_weights / class_weights.sum() * 4\n",
    "    print(f\"\\n‚öñÔ∏è  Class weights (normalis√©s):\")\n",
    "    print(f\"   Classe 0: {class_weights[0]:.4f}\")\n",
    "    print(f\"   Classe 1: {class_weights[1]:.4f}\")\n",
    "    print(f\"   Classe 2: {class_weights[2]:.4f}\")\n",
    "    print(f\"   Classe 3: {class_weights[3]:.4f}\")\n",
    "else:\n",
    "    class_weights = np.ones(4, dtype=np.float32)  # Fallback: poids √©gaux si pas de labels valides\n",
    "    print(\"‚ö†Ô∏è  Pas de labels trouv√©s, utilisation de poids √©gaux\")\n",
    "\n",
    "# Datasets - utiliser BI_RADS (strings) car MammographyDataset.BI_RADS_MAPPING attend des strings\n",
    "# BI_RADS_Class est pour les class weights seulement\n",
    "train_dataset = MammographyDataset(df_train, image_col='ImagePaths', birads_col='BI_RADS',\n",
    "                                   target_size=TARGET_SIZE, augment=True)\n",
    "val_dataset = MammographyDataset(df_val, image_col='ImagePaths', birads_col='BI_RADS',\n",
    "                                 target_size=TARGET_SIZE, augment=False)\n",
    "test_dataset = MammographyDataset(df_test, image_col='ImagePaths', birads_col='BI_RADS',\n",
    "                                  target_size=TARGET_SIZE, augment=False)\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "print(f\"‚úì Datasets cr√©√©s\\n  Train loader: {len(train_loader)} batches\")\n",
    "print(f\"  Val loader: {len(val_loader)} batches\")\n",
    "print(f\"  Test loader: {len(test_loader)} batches\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09ce745d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d6dcfd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "√âTAPE 3: ENTRA√éNEMENT MOD√àLES - PRIORIT√â A\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"√âTAPE 3: ENTRA√éNEMENT MOD√àLES - PRIORIT√â A\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "REDUCED_BATCH_SIZE = 8\n",
    "\n",
    "train_loader_reduced = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=REDUCED_BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader_reduced = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=REDUCED_BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c42570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ENTRA√éNEMENT: RESNET50\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Epoch 1/10 - Model: resnet50\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 419/419 [53:07<00:00,  7.61s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [09:30<00:00,  6.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 60.0647\n",
      "Mean AP: 0.2536 | Accuracy: 0.6820\n",
      "F1 (weighted): 0.5531 | Kappa: 0.0000\n",
      "AP per class: ['0.682', '0.000', '0.000', '0.332']\n",
      "‚úì Meilleur AP trouv√©! Sauvegard√©.\n",
      "\n",
      "============================================================\n",
      "Epoch 2/10 - Model: resnet50\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   9%|‚ñâ         | 37/419 [03:55<40:05,  6.30s/it]"
     ]
    }
   ],
   "source": [
    "models_priority_a = [\n",
    "    'resnet50',\n",
    "    'inception_v3',\n",
    "    'densenet121',\n",
    "    'efficientnet_b0'\n",
    "]\n",
    "\n",
    "results_priority_a = {}\n",
    "\n",
    "for model_name in models_priority_a:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ENTRA√éNEMENT: {model_name.upper()}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    try:\n",
    "        # üî• Nettoyage GPU AVANT chaque mod√®le\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        # Cr√©e le mod√®le\n",
    "        model = create_model(model_name, pretrained=True).to(DEVICE)\n",
    "\n",
    "        # Initialise le trainer\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            train_loader=train_loader_reduced,\n",
    "            val_loader=val_loader_reduced,\n",
    "            model_name=model_name,\n",
    "            lr=1e-3,\n",
    "            weight_decay=1e-4,\n",
    "            use_focal=False,\n",
    "            class_weights=class_weights\n",
    "        )\n",
    "\n",
    "        # Entra√Ænement\n",
    "        metrics, probs, labels, preds = trainer.train(\n",
    "            num_epochs=10,\n",
    "            early_stopping_patience=5\n",
    "        )\n",
    "\n",
    "        # Sauvegarde RAM + disque (pro)\n",
    "        results_priority_a[model_name] = metrics\n",
    "        torch.save(model.state_dict(), f\"{model_name}_best.pth\")\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        print(f\"‚ùå RuntimeError ({model_name}): {e}\")\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur ({model_name}): {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5796b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "√âTAPE 4: √âVALUATION COMPL√àTE\n",
      "======================================================================\n",
      "\n",
      "‚úì √âvaluation termin√©e\n"
     ]
    }
   ],
   "source": [
    "# √âTAPE 4: √âVALUATION ET VISUALISATION\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"√âTAPE 4: √âVALUATION COMPL√àTE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "evaluator = BiRadsEvaluator()\n",
    "\n",
    "for model_name, results in results_priority_a.items():\n",
    "    print(f\"\\n{'‚îÄ'*60}\")\n",
    "    print(f\"√âVALUATION: {model_name.upper()}\")\n",
    "    print(f\"{'‚îÄ'*60}\")\n",
    "    \n",
    "    # Affiche m√©triques d√©taill√©es\n",
    "    evaluator.print_detailed_metrics(\n",
    "        results['labels'], \n",
    "        results['preds'], \n",
    "        results['probs'],\n",
    "        model_name=model_name\n",
    "    )\n",
    "    \n",
    "    # Visualisations\n",
    "    fig_cm = evaluator.plot_confusion_matrix(results['labels'], results['preds'], \n",
    "                                             title=f'{model_name} - Confusion Matrix')\n",
    "    fig_pr = evaluator.plot_pr_curves(results['labels'], results['probs'])\n",
    "    fig_hist = evaluator.plot_training_history(results['trainer'].history, model_name=model_name)\n",
    "    \n",
    "    # Sauvegarde figures\n",
    "    fig_cm.savefig(f'cm_{model_name}.png', dpi=100, bbox_inches='tight')\n",
    "    fig_pr.savefig(f'pr_curves_{model_name}.png', dpi=100, bbox_inches='tight')\n",
    "    fig_hist.savefig(f'training_history_{model_name}.png', dpi=100, bbox_inches='tight')\n",
    "    \n",
    "    print(f\"‚úì Figures sauvegard√©es: cm_{model_name}.png, pr_curves_{model_name}.png, training_history_{model_name}.png\")\n",
    "\n",
    "print(f\"\\n‚úì √âvaluation termin√©e\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3010a71e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "√âTAPE 5: COMPARAISON DES MOD√àLES\n",
      "======================================================================\n",
      "\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "\n",
      "‚úì Comparaison sauvegard√©e: model_comparison.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# √âTAPE 5: COMPARAISON DES MOD√àLES\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"√âTAPE 5: COMPARAISON DES MOD√àLES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "comparison_data = []\n",
    "for model_name, results in results_priority_a.items():\n",
    "    metrics = results['metrics']\n",
    "    comparison_data.append({\n",
    "        'Model': model_name,\n",
    "        'Mean AP': f\"{metrics['mean_ap']:.4f}\",\n",
    "        'Accuracy': f\"{metrics['accuracy']:.4f}\",\n",
    "        'F1 (weighted)': f\"{metrics['f1']:.4f}\",\n",
    "        'Kappa': f\"{metrics['kappa']:.4f}\"\n",
    "    })\n",
    "\n",
    "df_comparison = pd.DataFrame(comparison_data)\n",
    "print(f\"\\n{df_comparison.to_string(index=False)}\\n\")\n",
    "\n",
    "# Graphique comparatif\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# AP comparison\n",
    "model_names = list(results_priority_a.keys())\n",
    "mean_aps = [results_priority_a[m]['metrics']['mean_ap'] for m in model_names]\n",
    "accuracies = [results_priority_a[m]['metrics']['accuracy'] for m in model_names]\n",
    "\n",
    "axes[0].bar(model_names, mean_aps, color='steelblue', alpha=0.7)\n",
    "axes[0].set_ylabel('Mean AP')\n",
    "axes[0].set_title('Average Precision Comparison')\n",
    "axes[0].set_ylim([0, 1])\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "for i, v in enumerate(mean_aps):\n",
    "    axes[0].text(i, v + 0.02, f'{v:.3f}', ha='center')\n",
    "\n",
    "# Accuracy comparison\n",
    "axes[1].bar(model_names, accuracies, color='coral', alpha=0.7)\n",
    "axes[1].set_ylabel('Accuracy')\n",
    "axes[1].set_title('Accuracy Comparison')\n",
    "axes[1].set_ylim([0, 1])\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "for i, v in enumerate(accuracies):\n",
    "    axes[1].text(i, v + 0.02, f'{v:.3f}', ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('model_comparison.png', dpi=100, bbox_inches='tight')\n",
    "print(f\"‚úì Comparaison sauvegard√©e: model_comparison.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7884c2b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "√âTAPE 6: ENSEMBLE PAR SOFT VOTING\n",
      "======================================================================\n"
     ]
    },
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAxisError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m all_probs = np.array([results_priority_a[m][\u001b[33m'\u001b[39m\u001b[33mprobs\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m results_priority_a.keys()])\n\u001b[32m      8\u001b[39m ensemble_probs = np.mean(all_probs, axis=\u001b[32m0\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m ensemble_preds = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mensemble_probs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m ensemble_labels = results_priority_a[\u001b[38;5;28mlist\u001b[39m(results_priority_a.keys())[\u001b[32m0\u001b[39m]][\u001b[33m'\u001b[39m\u001b[33mlabels\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# √âvalue ensemble\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Dataset\\Nouveaudossier\\venv\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:1342\u001b[39m, in \u001b[36margmax\u001b[39m\u001b[34m(a, axis, out, keepdims)\u001b[39m\n\u001b[32m   1253\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1254\u001b[39m \u001b[33;03mReturns the indices of the maximum values along an axis.\u001b[39;00m\n\u001b[32m   1255\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1339\u001b[39m \u001b[33;03m(2, 1, 4)\u001b[39;00m\n\u001b[32m   1340\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1341\u001b[39m kwds = {\u001b[33m'\u001b[39m\u001b[33mkeepdims\u001b[39m\u001b[33m'\u001b[39m: keepdims} \u001b[38;5;28;01mif\u001b[39;00m keepdims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np._NoValue \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[32m-> \u001b[39m\u001b[32m1342\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43margmax\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Dataset\\Nouveaudossier\\venv\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:57\u001b[39m, in \u001b[36m_wrapfunc\u001b[39m\u001b[34m(obj, method, *args, **kwds)\u001b[39m\n\u001b[32m     54\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, *args, **kwds)\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m     59\u001b[39m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[32m     60\u001b[39m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     64\u001b[39m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[32m     65\u001b[39m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[32m     66\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, *args, **kwds)\n",
      "\u001b[31mAxisError\u001b[39m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "# √âTAPE 6: ENSEMBLE & SOFT VOTING (Priorit√© C)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"√âTAPE 6: ENSEMBLE PAR SOFT VOTING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Soft voting: moyenne des probs de tous les mod√®les\n",
    "all_probs = np.array([results_priority_a[m]['probs'] for m in results_priority_a.keys()])\n",
    "ensemble_probs = np.mean(all_probs, axis=0)\n",
    "ensemble_preds = np.argmax(ensemble_probs, axis=1)\n",
    "ensemble_labels = results_priority_a[list(results_priority_a.keys())[0]]['labels']\n",
    "\n",
    "# √âvalue ensemble\n",
    "evaluator.print_detailed_metrics(\n",
    "    ensemble_labels,\n",
    "    ensemble_preds,\n",
    "    ensemble_probs,\n",
    "    model_name='ENSEMBLE (Soft Voting)'\n",
    ")\n",
    "\n",
    "# Visualisations ensemble\n",
    "fig_cm_ens = evaluator.plot_confusion_matrix(ensemble_labels, ensemble_preds,\n",
    "                                             title='Ensemble (Soft Voting) - Confusion Matrix')\n",
    "fig_pr_ens = evaluator.plot_pr_curves(ensemble_labels, ensemble_probs)\n",
    "\n",
    "fig_cm_ens.savefig('cm_ensemble.png', dpi=100, bbox_inches='tight')\n",
    "fig_pr_ens.savefig('pr_curves_ensemble.png', dpi=100, bbox_inches='tight')\n",
    "\n",
    "print(f\"‚úì Ensemble soft voting √©valu√© et visualis√©\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9102f454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# √âTAPE 7: CALIBRATION & CONFIANCE (Important en clinique)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"√âTAPE 7: CALIBRATION & SCORES DE CONFIANCE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "class ConfidenceCalibrator:\n",
    "    \"\"\"\n",
    "    Temperature scaling pour calibration\n",
    "    Am√©liore la confiance des pr√©dictions\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def temperature_scaling(probs, temperature=1.0):\n",
    "        \"\"\"Applique temperature scaling\"\"\"\n",
    "        # Logits normalis√©s\n",
    "        probs_scaled = np.exp(np.log(probs + 1e-8) / temperature)\n",
    "        probs_scaled = probs_scaled / probs_scaled.sum(axis=1, keepdims=True)\n",
    "        return probs_scaled\n",
    "    \n",
    "    @staticmethod\n",
    "    def confidence_with_uncertainty(probs, uncertainty_method='entropy'):\n",
    "        \"\"\"\n",
    "        Retourne pr√©diction + score de confiance\n",
    "        uncertainty_method: 'entropy' ou 'margin'\n",
    "        \"\"\"\n",
    "        preds = np.argmax(probs, axis=1)\n",
    "        max_probs = np.max(probs, axis=1)\n",
    "        \n",
    "        if uncertainty_method == 'entropy':\n",
    "            uncertainty = -np.sum(probs * np.log(probs + 1e-8), axis=1)\n",
    "            confidence = 1.0 - (uncertainty / np.log(4))  # Normalize by max entropy\n",
    "        else:  # margin\n",
    "            sorted_probs = np.sort(probs, axis=1)\n",
    "            confidence = sorted_probs[:, -1] - sorted_probs[:, -2]\n",
    "        \n",
    "        return preds, max_probs, confidence\n",
    "\n",
    "calibrator = ConfidenceCalibrator()\n",
    "\n",
    "# Apply calibration aux pr√©dictions ensemble\n",
    "ensemble_probs_calibrated = calibrator.temperature_scaling(ensemble_probs, temperature=1.2)\n",
    "ensemble_preds_cal, max_probs, confidence = calibrator.confidence_with_uncertainty(\n",
    "    ensemble_probs_calibrated, uncertainty_method='entropy'\n",
    ")\n",
    "\n",
    "# Affiche distribution de confiance\n",
    "print(f\"\\nDistribution de confiance (ensemble calibr√©):\")\n",
    "print(f\"  Min: {confidence.min():.4f}\")\n",
    "print(f\"  Mean: {confidence.mean():.4f}\")\n",
    "print(f\"  Max: {confidence.max():.4f}\")\n",
    "print(f\"  Median: {np.median(confidence):.4f}\")\n",
    "\n",
    "# Visualise\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "axes[0].hist(confidence, bins=30, edgecolor='black', alpha=0.7, color='skyblue')\n",
    "axes[0].set_xlabel('Confidence Score')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Confidence Distribution (Ensemble)')\n",
    "axes[0].grid(axis='y')\n",
    "\n",
    "# Accuracy vs Confidence\n",
    "sorted_indices = np.argsort(confidence)\n",
    "cumulative_correct = np.cumsum(ensemble_preds[sorted_indices] == ensemble_labels[sorted_indices])\n",
    "percentages = cumulative_correct / np.arange(1, len(sorted_indices) + 1)\n",
    "\n",
    "axes[1].plot(confidence[sorted_indices], percentages, linewidth=2, color='steelblue')\n",
    "axes[1].set_xlabel('Confidence Threshold')\n",
    "axes[1].set_ylabel('Accuracy of High-Confidence Predictions')\n",
    "axes[1].set_title('Accuracy vs Confidence (Reliability Diagram)')\n",
    "axes[1].grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('calibration_confidence.png', dpi=100, bbox_inches='tight')\n",
    "print(f\"‚úì Calibration et confiance sauvegard√©es\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798b72d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# √âTAPE 8: FEUILLE DE ROUTE POUR AM√âLIORATIONS (Priorit√© B)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FEUILLE DE ROUTE D'AM√âLIORATIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "roadmap = \"\"\"\n",
    "PRIORIT√â B - Architectures Modernes (√† impl√©menter apr√®s Priorit√© A)\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "1. EfficientNetV2-S/M (Recommended)\n",
    "   - Param√®tres: torch.hub import efficientnet_v2_s\n",
    "   - Avantages: Meilleure efficacit√©, moins de param√®tres, plus rapide\n",
    "   - Learning Rate: 0.0005 (plus petit que ResNet)\n",
    "   - Batch Size: 64 (peut √™tre 128 avec mixed precision)\n",
    "   \n",
    "   Code:\n",
    "   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "   from torchvision.models import efficientnet_v2_s\n",
    "   backbone = efficientnet_v2_s(weights=EfficientNet_V2_S_Weights.IMAGENET1K_V1)\n",
    "   \n",
    "2. Vision Transformer (ViT-Base ou Swin-Transformer)\n",
    "   - ViT-B/16 si tu as GPU puissant, sinon Swin-T\n",
    "   - Avantages: Meilleure g√©n√©ralisation, capture relations globales\n",
    "   - Learning Rate: 0.00005 (tr√®s petit pour Transformers)\n",
    "   - Warmup: 500 steps conseill√©\n",
    "   - Batch Size: 32-64 (tr√®s gourmand en m√©moire)\n",
    "   \n",
    "   Code:\n",
    "   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "   from torchvision.models import swin_t\n",
    "   backbone = swin_t(weights=Swin_T_Weights.IMAGENET1K_V1)\n",
    "\n",
    "3. Multi-Task Learning (MTL)\n",
    "   - Head 1: BI-RADS (4 classes) - CrossEntropy\n",
    "   - Head 2: Density Percentage (0-100) - MSE regression\n",
    "   - Head 3: (Optional) Anomaly presence - BCE\n",
    "   \n",
    "   Loss = Œ± * CrossEntropy(BI-RADS) + Œ≤ * MSE(Density) + Œ≥ * BCE(Anomaly)\n",
    "   Poids recommand√©s: Œ±=1.0, Œ≤=0.5, Œ≥=0.3\n",
    "   \n",
    "4. Self-Supervised Pretraining (SimCLR)\n",
    "   - Tr√®s utile si labels limit√©s\n",
    "   - Entra√Æne sur tout le corpus mammographique sans labels\n",
    "   - Fine-tune ensuite avec labels BI-RADS\n",
    "   - Gain attendu: +3-5% AP\n",
    "\n",
    "PRIORIT√â C - Methods Compl√©mentaires\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "5. Multi-View Aggregation (tu as LCC, RCC, MLO paths)\n",
    "   - Entra√Æne 2 heads: LCC/RCC et MLO\n",
    "   - Soft voting au level examen:\n",
    "     prediction_exam = softmax(avg(logits_lcc, logits_rcc, logits_mlo))\n",
    "   \n",
    "6. Explainability - Grad-CAM\n",
    "   - Visualise zones d√©cisives pour diagnostic\n",
    "   - Important pour acceptabilit√© clinique\n",
    "   \n",
    "7. External Validation\n",
    "   - Test sur RSNA/Kaggle si accessible\n",
    "   - √âvalue robustesse √† domaines diff√©rents\n",
    "\n",
    "HYPERPARAM√àTRES RECOMMAND√âS\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "Optimizer: Adam\n",
    "Learning Rate Schedule:\n",
    "  - Initial LR: 0.001 (ResNet/DenseNet), 0.0005 (EfficientNet), 0.00005 (Transformers)\n",
    "  - Schedule: CosineAnnealing avec warmup\n",
    "  - Warmup epochs: 2-5\n",
    "\n",
    "Batch Size:\n",
    "  - ResNet50: 64\n",
    "  - DenseNet121: 64\n",
    "  - EfficientNet: 64-128\n",
    "  - Transformers: 32-64\n",
    "\n",
    "Regularization:\n",
    "  - Weight Decay: 1e-4 to 1e-5\n",
    "  - Dropout: 0.5 (in head)\n",
    "  - Cutout/Mixup: Recommand√© pour augmentation\n",
    "\n",
    "Image Size:\n",
    "  - 224√ó224: Baseline (article)\n",
    "  - 320√ó320: Meilleure performance mais plus lent\n",
    "  - 384√ó384: Optimum pour Transformers mais tr√®s gourmand\n",
    "\n",
    "Epochs: 30-50 avec early stopping\n",
    "\n",
    "M√âTRIQUES DE SUIVI\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "- Mean AP (0-1): M√©trique principale\n",
    "- Accuracy (0-1): Baseline\n",
    "- F1 Score (weighted): Tient compte imbalance\n",
    "- Cohen's Kappa: Accord inter-annotateur\n",
    "- ROC-AUC: Robustesse aux seuils\n",
    "- Per-class AP: Debug imbalance\n",
    "\n",
    "PROCHAINES √âTAPES\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "1. ‚úì Impl√©mentation Priorit√© A (FAIT)\n",
    "2. ‚Üí Tester Priorit√© B mod√®les\n",
    "3. ‚Üí Comparer temps entra√Ænement vs performance\n",
    "4. ‚Üí Si temps: impl√©menter Multi-Task Learning\n",
    "5. ‚Üí Validation externe sur dataset RSNA/Kaggle\n",
    "\"\"\"\n",
    "\n",
    "print(roadmap)\n",
    "\n",
    "# Sauvegarde dans fichier\n",
    "with open('ROADMAP_IMPROVEMENTS.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(roadmap)\n",
    "\n",
    "print(f\"\\n‚úì Feuille de route sauvegard√©e: ROADMAP_IMPROVEMENTS.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d4a13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# √âTAPE 9: R√âSUM√â FINAL & EXPORT R√âSULTATS\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"R√âSUM√â FINAL & EXPORT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Cr√©e rapport Excel avec tous les r√©sultats\n",
    "summary_data = []\n",
    "\n",
    "for model_name, results in results_priority_a.items():\n",
    "    metrics = results['metrics']\n",
    "    summary_data.append({\n",
    "        'Model': model_name,\n",
    "        'Mean AP': f\"{metrics['mean_ap']:.4f}\",\n",
    "        'BI-RADS 1 AP': f\"{metrics['ap_per_class'][0]:.4f}\",\n",
    "        'BI-RADS 2 AP': f\"{metrics['ap_per_class'][1]:.4f}\",\n",
    "        'BI-RADS 3 AP': f\"{metrics['ap_per_class'][2]:.4f}\",\n",
    "        'BI-RADS 4 AP': f\"{metrics['ap_per_class'][3]:.4f}\",\n",
    "        'Accuracy': f\"{metrics['accuracy']:.4f}\",\n",
    "        'F1 Weighted': f\"{metrics['f1']:.4f}\",\n",
    "        'Cohen Kappa': f\"{metrics['kappa']:.4f}\"\n",
    "    })\n",
    "\n",
    "# Ajoute ensemble\n",
    "ensemble_ap = average_precision_score(\n",
    "    label_binarize(ensemble_labels, classes=[0, 1, 2, 3]),\n",
    "    ensemble_probs,\n",
    "    average='macro'\n",
    ")\n",
    "ensemble_acc = accuracy_score(ensemble_labels, ensemble_preds)\n",
    "ensemble_f1 = f1_score(ensemble_labels, ensemble_preds, average='weighted')\n",
    "ensemble_kappa = cohen_kappa_score(ensemble_labels, ensemble_preds)\n",
    "\n",
    "summary_data.append({\n",
    "    'Model': 'ENSEMBLE',\n",
    "    'Mean AP': f\"{ensemble_ap:.4f}\",\n",
    "    'BI-RADS 1 AP': '‚Äî',\n",
    "    'BI-RADS 2 AP': '‚Äî',\n",
    "    'BI-RADS 3 AP': '‚Äî',\n",
    "    'BI-RADS 4 AP': '‚Äî',\n",
    "    'Accuracy': f\"{ensemble_acc:.4f}\",\n",
    "    'F1 Weighted': f\"{ensemble_f1:.4f}\",\n",
    "    'Cohen Kappa': f\"{ensemble_kappa:.4f}\"\n",
    "})\n",
    "\n",
    "df_summary = pd.DataFrame(summary_data)\n",
    "\n",
    "# Affiche tableau\n",
    "print(f\"\\n{df_summary.to_string(index=False)}\\n\")\n",
    "\n",
    "# Sauvegarde Excel si possible\n",
    "try:\n",
    "    df_summary.to_excel('BI_RADS_Results_Summary.xlsx', index=False)\n",
    "    print(\"‚úì R√©sum√© sauvegard√©: BI_RADS_Results_Summary.xlsx\")\n",
    "except:\n",
    "    df_summary.to_csv('BI_RADS_Results_Summary.csv', index=False)\n",
    "    print(\"‚úì R√©sum√© sauvegard√©: BI_RADS_Results_Summary.csv\")\n",
    "\n",
    "# Sauvegarde pr√©dictions pour analyse externe\n",
    "predictions_df = pd.DataFrame({\n",
    "    'True_Label': ensemble_labels,\n",
    "    'Predicted_Label': ensemble_preds,\n",
    "    'Confidence': confidence,\n",
    "    'BI_RADS_1_Prob': ensemble_probs_calibrated[:, 0],\n",
    "    'BI_RADS_2_Prob': ensemble_probs_calibrated[:, 1],\n",
    "    'BI_RADS_3_Prob': ensemble_probs_calibrated[:, 2],\n",
    "    'BI_RADS_4_Prob': ensemble_probs_calibrated[:, 3],\n",
    "})\n",
    "\n",
    "predictions_df.to_csv('ensemble_predictions.csv', index=False)\n",
    "print(\"‚úì Pr√©dictions sauvegard√©es: ensemble_predictions.csv\")\n",
    "\n",
    "# Rapport final\n",
    "print(f\"\"\"\n",
    "{'='*70}\n",
    "RAPPORT FINAL - CLASSIFICATION BI-RADS\n",
    "{'='*70}\n",
    "\n",
    "ARCHITECTURE BASELINE (R√©plication article):\n",
    "  - Mod√®les impl√©ment√©s: ResNet50, InceptionV3, DenseNet121, EfficientNet\n",
    "  - M√©triques: AP, Accuracy, F1, Cohen's Kappa (comme article)\n",
    "  - Ensemble Soft Voting: ACTIV√â (agr√©gation probabilit√©s)\n",
    "\n",
    "DONN√âES:\n",
    "  - Changement automatique E: ‚Üí D: (‚úì)\n",
    "  - Gestion images manquantes: Sans blocage, fallback (‚úì)\n",
    "  - Split: 70% train, 15% val, 15% test\n",
    "\n",
    "R√âSULTATS CL√âS:\n",
    "  - Meilleur mod√®le simple: {df_summary.iloc[:-1].loc[df_summary.iloc[:-1]['Mean AP'].astype(float).idxmax(), 'Model']}\n",
    "  - Ensemble Soft Voting AP: {ensemble_ap:.4f}\n",
    "  - Ensemble Accuracy: {ensemble_acc:.4f}\n",
    "\n",
    "FICHIERS G√âN√âR√âS:\n",
    "  ‚úì best_*.pt: Poids des meilleurs mod√®les\n",
    "  ‚úì cm_*.png: Matrices de confusion\n",
    "  ‚úì pr_curves_*.png: Courbes Pr√©cision-Recall (4 classes)\n",
    "  ‚úì training_history_*.png: Loss et m√©triques par epoch\n",
    "  ‚úì model_comparison.png: Comparaison AP/Accuracy\n",
    "  ‚úì calibration_confidence.png: Distribution de confiance\n",
    "  ‚úì ensemble_predictions.csv: Toutes les pr√©dictions + confiance\n",
    "  ‚úì BI_RADS_Results_Summary.xlsx/csv: Tableau r√©sum√©\n",
    "  ‚úì ROADMAP_IMPROVEMENTS.txt: Plan d√©taill√© Priorit√©s B & C\n",
    "\n",
    "PROCHAINES √âTAPES:\n",
    "  1. Charger dataset complet (pas exemple) dans df\n",
    "  2. Tester Priorit√© B mod√®les (EfficientNetV2, ViT)\n",
    "  3. Impl√©menter Multi-Task Learning si labels densit√© disponibles\n",
    "  4. Validation externe sur RSNA/Kaggle\n",
    "  5. Fine-tune avec Self-Supervised Pretraining (SimCLR)\n",
    "\n",
    "{'='*70}\n",
    "\"\"\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
